{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7635e2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e79d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "from tqdm.notebook  import tqdm\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import pylev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34850ad8",
   "metadata": {},
   "source": [
    "# Load text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = set()\n",
    "words = []\n",
    "limit = int(1e6)\n",
    "\n",
    "text = open(\"list/french.txt\", \"rb\").read().decode(\"utf8\").lower()\n",
    "unprocessed_words = re.split(\"\\s\", text)[0:limit]\n",
    "for word in unprocessed_words:\n",
    "    if len(word) < 4:\n",
    "        continue\n",
    "    if any([i not in string.ascii_lowercase for i in word]):\n",
    "        continue\n",
    "    characters |= set(word)\n",
    "    words.append(word)\n",
    "\n",
    "characters = sorted(list(characters))\n",
    "print(f\"characters : {len(characters)}\")\n",
    "print(characters)\n",
    "print(f\"nb words : {len(words)}\")\n",
    "print(words[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d84aeb",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21386cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(word, n):\n",
    "    return [word[i:i+n] for i in range(0, len(word) - n + 1)]\n",
    "n_grams(words[5], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e166f9a",
   "metadata": {},
   "source": [
    "# Probability tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e733dbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_probability_table(chain):\n",
    "    counter = Counter(chain)\n",
    "    p = np.zeros(len(counter.most_common(1)[0][0]) * [len(characters)])\n",
    "    for w in counter:\n",
    "        pos = tuple([characters.index(i) for i in w])\n",
    "        p[pos] = counter[w]\n",
    "    return p\n",
    "\n",
    "chain_s1 = itertools.chain(word[:1] for word in tqdm(words))\n",
    "chain_s2 = itertools.chain(word[:2] for word in tqdm(words))\n",
    "chain_s3 = itertools.chain(word[:3] for word in tqdm(words))\n",
    "chain_m4 = itertools.chain.from_iterable(n_grams(word, 4) for word in tqdm(words))\n",
    "chain_e3 = itertools.chain(word[-3:] for word in tqdm(words))\n",
    "chain_e2 = itertools.chain(word[-2:] for word in tqdm(words))\n",
    "\n",
    "ps1 = create_probability_table(chain_s1)\n",
    "ps2 = create_probability_table(chain_s2)\n",
    "ps3 = create_probability_table(chain_s3)\n",
    "pm4 = create_probability_table(chain_m4)\n",
    "pe3 = create_probability_table(chain_e3)\n",
    "pe2 = create_probability_table(chain_e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(p):\n",
    "    a = p.reshape(-1)\n",
    "    print(f\"{np.sum(a!=0)}/{a.shape[0]}\")\n",
    "    \n",
    "print_stats(ps1)\n",
    "print_stats(ps2)\n",
    "print_stats(ps3)\n",
    "print_stats(pm4)\n",
    "print_stats(pe3)\n",
    "print_stats(pe2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e93bddd",
   "metadata": {},
   "source": [
    "# Generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdb8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(n, s=\"\", laplace=1e-1):\n",
    "    s = s.lower()\n",
    "    for i in range(n):\n",
    "        # get the previous characters indices\n",
    "        if len(s) >= 1:\n",
    "            n_minus_1 = characters.index(s[len(s)-1])\n",
    "        if len(s) >= 2:\n",
    "            n_minus_2 = characters.index(s[len(s)-2])\n",
    "        if len(s) >= 2:\n",
    "            n_minus_3 = characters.index(s[len(s)-3])\n",
    "        \n",
    "        # select the probability table\n",
    "        \n",
    "        # begining of the word\n",
    "        if len(s) <= 0:\n",
    "            p = ps1\n",
    "        elif len(s) <= 1:\n",
    "            p = ps2[n_minus_1, :]\n",
    "        elif len(s) <= 2:\n",
    "            p = ps3[n_minus_2, n_minus_1, :]\n",
    "        # end of the word\n",
    "        elif len(s) >= n - 1:\n",
    "            p = pe2[n_minus_1, :]\n",
    "        elif len(s) >= n - 2:\n",
    "            p = pe3[n_minus_2, n_minus_1, :]\n",
    "        # middle of the word\n",
    "        else:\n",
    "            p = pm4[n_minus_3, n_minus_2, n_minus_1, :]\n",
    "\n",
    "        # laplace smoothing\n",
    "        p = p.copy()\n",
    "        p += laplace\n",
    "        for i in range(10):\n",
    "            p = p / p.sum()\n",
    "        \n",
    "        # select the next character\n",
    "        s += np.random.choice(characters, p=p)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probability(w):\n",
    "    def prob(p, c, laplace=1e-1):\n",
    "        sum_ = p.sum() + laplace\n",
    "        qte = p[c] + len(p.reshape(-1)) * laplace\n",
    "        return np.log(qte / sum_)\n",
    "    \n",
    "    p = 0\n",
    "    \n",
    "    characters_indices = [characters.index(wi) for wi in w]\n",
    "    \n",
    "    # start letters probability\n",
    "    if len(characters_indices) > 0:\n",
    "        p += prob(ps1, (characters_indices[0],))\n",
    "    \n",
    "    if len(characters_indices) > 1:\n",
    "        p += prob(ps2, (characters_indices[0], characters_indices[1]))\n",
    "        \n",
    "    if len(characters_indices) > 2:\n",
    "        p += prob(ps3, (characters_indices[0], characters_indices[1], characters_indices[2]))\n",
    "        \n",
    "    # end letters probability\n",
    "    if len(characters_indices) > 1:\n",
    "        p += prob(pe2, (characters_indices[-2], characters_indices[-1],))\n",
    "    \n",
    "    if len(characters_indices) > 2:\n",
    "        p += prob(pe3, (characters_indices[-3], characters_indices[-2], characters_indices[-1],))\n",
    "        \n",
    "    # in-between probability\n",
    "    if len(characters_indices) > 3:\n",
    "        for ch in [tuple(characters_indices[i:i+4]) for i in range(len(characters_indices)-3)]:\n",
    "            p += prob(pm4, ch)\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c732392",
   "metadata": {},
   "source": [
    "# Use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08677a0d",
   "metadata": {},
   "source": [
    "## Generate words based on this word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ceda1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(generate(int(np.random.randint(4, 15))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85a15a",
   "metadata": {},
   "source": [
    "## Generate words starting by x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4876dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(generate(2, \"etienne\").title())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584cc641",
   "metadata": {},
   "source": [
    "## Find anagram of a word and sort them by their probability of occuring in the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd841320",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"maxime\"\n",
    "\n",
    "def perm(word):\n",
    "    wa = list(word)\n",
    "    random.shuffle(wa)\n",
    "    return \"\".join(wa) \n",
    "\n",
    "\n",
    "found = set()\n",
    "probabilities = []\n",
    "\n",
    "iterator = iter(bool, True)\n",
    "iterator = itertools.permutations(word, len(word))\n",
    "\n",
    "for i, _ in enumerate(iterator, start=1):\n",
    "    p = perm(word)\n",
    "    \n",
    "    if i > 1000000:\n",
    "        break\n",
    "    if p in found:\n",
    "        continue\n",
    "    found.add(p)\n",
    "    \n",
    "    probabilities.append((compute_probability(p), p))\n",
    "    \n",
    "probabilities.sort(key=lambda c: -c[0])\n",
    "    \n",
    "for p in probabilities[0:100]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07bd28",
   "metadata": {},
   "source": [
    "## Generate a lot of words in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e7dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = [generate(8) for w in tqdm(range(10000))]\n",
    "open(\"generated/words.txt\", \"w\").write(\"\\r\\n\".join(ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078ef87",
   "metadata": {},
   "source": [
    "## Find anagrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24866a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_combinations_util(arr, index, num, reducedNum):\n",
    "    # https://www.geeksforgeeks.org/find-all-combinations-that-adds-upto-given-number-2/\n",
    "    if (reducedNum < 0):\n",
    "        return\n",
    "    if (reducedNum == 0):\n",
    "        yield arr[0:index]\n",
    "        return\n",
    "    prev = 1 if index == 0 else arr[index - 1]\n",
    "    for k in range(prev, num + 1):\n",
    "        arr[index] = k\n",
    "        for i in sum_combinations_util(arr, index + 1, num, reducedNum - k):\n",
    "            yield i\n",
    "\n",
    "def sum_combinations(n, min_array_size=0, max_array_size=np.inf, min_array_value=0, max_array_value=np.inf):\n",
    "    for i in sum_combinations_util([0] * n, 0, n, n):\n",
    "        if len(i) < min_array_size:\n",
    "            continue\n",
    "        if len(i) > max_array_size:\n",
    "            continue\n",
    "        if min(i) < min_array_value:\n",
    "            continue\n",
    "        if max(i) > max_array_value:\n",
    "            continue\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d5b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(words)\n",
    "\n",
    "def words_iterator_of_sum_n(target, min_words, max_words, min_word_size, max_word_size):\n",
    "    n = len(target)\n",
    "    # remove word that have extra letters\n",
    "    filtered_words = []\n",
    "    for w in words:\n",
    "        if all(l in target for l in w):\n",
    "             filtered_words.append(w)\n",
    "    \n",
    "    # group word by size\n",
    "    words_by_size = defaultdict(list)\n",
    "    for word in filtered_words:\n",
    "        words_by_size[len(word)].append(word)\n",
    "    \n",
    "    # create pair for every words that have the same number of letters\n",
    "    for comb in sum_combinations(n, min_word_size, max_word_size, min_words, max_words):\n",
    "        words_list_combinations = [words_by_size[comb_i] for comb_i in comb]\n",
    "        for words_combination in itertools.product(*words_list_combinations):\n",
    "            yield words_combination\n",
    "    \n",
    "def compare(w1, w2):\n",
    "    # compute the levenshtein distance on the two strings\n",
    "    w1 = \"\".join(sorted(list(w1)))\n",
    "    w2 = \"\".join(sorted(list(w2)))\n",
    "    return pylev.levenshtein(w1, w2)\n",
    "\n",
    "\n",
    "def anagram_finder(target, min_words, max_words, min_word_size, max_word_size, minimal_dist, maximal_dist):\n",
    "    for words_combination in words_iterator_of_sum_n(target, min_word_size, max_word_size, min_words, max_words):\n",
    "        d = compare(\"\".join(words_combination), target)\n",
    "        if minimal_dist <= d <= maximal_dist:\n",
    "            yield words_combination, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50196e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"raphaelmargueron\"\n",
    "\n",
    "settings = {\n",
    "    \"min_words\": 1,\n",
    "    \"max_words\": 3,\n",
    "    \"min_word_size\": 5,\n",
    "    \"max_word_size\": np.inf,\n",
    "    \"minimal_dist\": 0,\n",
    "    \"maximal_dist\": 0,\n",
    "}\n",
    "\n",
    "for words_combination, d in anagram_finder(target, **settings):\n",
    "    print([len(w) for w in words_combination], words_combination, d)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f30c937b6abe364228d7429c1d0c7a31858aa0c195e6a804665f69f0c413ac39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
